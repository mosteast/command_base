#!/usr/bin/env node

"use strict";

const fs = require("fs/promises");
const path = require("path");
const { spawn, spawnSync } = require("child_process");
const os = require("os");
const fs_sync = require("fs");
const yargs_factory = require("yargs/yargs");
const { expand_patterns } = require("../utility/_ai_cli_utils");
const {
  convert_markdown_to_plain_text,
} = require("../lib/text_processing/markdown_to_plain_text");

const index_tts_default_voice_path = path.resolve(
  __dirname,
  "../lib/tts/index_tts/speaker/francis_underwood.m4a",
);

const XTTS_SUPPORTED_VOICE_EXTENSIONS = new Set([
  ".wav",
  ".flac",
  ".ogg",
  ".mp3",
]);

const shared_cli_option_docs = {
  engine_help: {
    flag: "--engine-help <engine>",
    description:
      "Show extended documentation for an engine (index_tts|xtts|piper|vibe_voice|all) and exit.",
  },
  text: {
    flag: "--text <string>",
    description:
      "Inline text to synthesize (mutually exclusive with --text-file and positional file/glob inputs).",
  },
  text_file: {
    flag: "--text-file <path>",
    description:
      "Read input text from a file (mutually exclusive with --text and positional inputs).",
  },
  output: {
    flag: "--output <path>",
    description:
      "Destination wav file or directory (directory required when processing multiple inputs).",
  },
  voice: {
    flag: "--voice <path>",
    description:
      "Reference speaker audio file for cloning engines (IndexTTS, XTTS, VibeVoice).",
  },
  speaker: {
    flag: "--speaker <name>",
    description:
      "Named XTTS speaker preset (ignored when --voice provides custom cloning audio).",
  },
  lang: {
    flag: "--lang <code>",
    description: "Language code hint forwarded to the engine (en|zh-cn|auto).",
  },
  speed: {
    flag: "--speed <number>",
    description:
      "Playback speed multiplier applied after synthesis (must be positive).",
  },
  temperature: {
    flag: "--temperature <number>",
    description:
      "XTTS sampling temperature controlling output diversity (higher adds variety).",
  },
  device: {
    flag: "--device <target>",
    description:
      "Execution device for XTTS (auto|cpu|cuda:0) and VibeVoice (auto|cpu|cuda|mps).",
  },
  python_bin: {
    flag: "--python-bin <path>",
    description:
      "Explicit Python interpreter for engines backed by Python (IndexTTS, XTTS, VibeVoice).",
  },
  refresh: {
    flag: "--refresh",
    description: "Overwrite existing output files (disabled by default).",
  },
  index_tts_home: {
    flag: "--index-tts-home <path>",
    description:
      "Local index-tts checkout directory for resolving scripts and checkpoints.",
  },
  index_tts_checkpoints: {
    flag: "--index-tts-checkpoints <path>",
    description:
      "Directory containing index-tts checkpoints (overrides defaults).",
  },
  index_tts_config: {
    flag: "--index-tts-config <path>",
    description:
      "Custom index-tts config.yaml path (defaults to <checkpoints>/config.yaml).",
  },
  emo_audio: {
    flag: "--emo-audio <path>",
    description: "IndexTTS emotion conditioning audio reference clip.",
  },
  emo_text: {
    flag: "--emo-text <string>",
    description: "Text prompt describing the desired emotion for IndexTTS.",
  },
  emo_vector: {
    flag: "--emo-vector <values>",
    description:
      "Comma separated or JSON array of eight floats for IndexTTS emotion control.",
  },
  emo_alpha: {
    flag: "--emo-alpha <number>",
    description: "Blend strength for IndexTTS emotion conditioning (0.0-1.0).",
  },
  index_tts_fp16: {
    flag: "--index-tts-fp16",
    description: "Enable half precision inference for IndexTTS when supported.",
  },
  index_tts_deepspeed: {
    flag: "--index-tts-deepspeed",
    description:
      "Enable DeepSpeed acceleration for IndexTTS (requires additional dependencies).",
  },
  index_tts_cuda_kernel: {
    flag: "--index-tts-cuda-kernel",
    description: "Allow IndexTTS to use optimized CUDA kernels when available.",
  },
  index_tts_random: {
    flag: "--index-tts-random",
    description:
      "Enable stochastic IndexTTS sampling at the cost of cloning fidelity.",
  },
  index_tts_max_segment: {
    flag: "--index-tts-max-segment <number>",
    description:
      "Maximum characters per IndexTTS segment before automatic chunking.",
  },
  piper_model: {
    flag: "--piper-model <path>",
    description: "Absolute path to the Piper ONNX model file.",
  },
  vibe_voice_model_dir: {
    flag: "--vibe_voice-model-dir <path>",
    description: "Directory containing local VibeVoice model weights.",
  },
  vibe_voice_processor_dir: {
    flag: "--vibe_voice-processor-dir <path>",
    description:
      "Optional directory for VibeVoice processor assets when stored separately.",
  },
  vibe_voice_cfg_scale: {
    flag: "--vibe_voice-cfg-scale <number>",
    description: "Classifier-free guidance scale for VibeVoice generation.",
  },
  vibe_voice_max_new: {
    flag: "--vibe_voice-max-new <number>",
    description:
      "Maximum number of tokens to generate for VibeVoice (optional).",
  },
  vibe_voice_ddpm_steps: {
    flag: "--vibe_voice-ddpm-steps <number>",
    description: "Diffusion step override for VibeVoice inference.",
  },
  vibe_voice_half: {
    flag: "--vibe_voice-half",
    description: "Run VibeVoice in half precision when hardware allows.",
  },
  vibe_voice_device: {
    flag: "--vibe_voice-device <target>",
    description: "Execution device hint for VibeVoice (auto|cpu|cuda|mps).",
  },
  vibe_voice_quiet: {
    flag: "--vibe_voice-quiet",
    description: "Silence VibeVoice progress output.",
  },
};

function engine_option_doc(engine_key, label) {
  return {
    flag: `--engine ${engine_key}`,
    description: `Select ${label} as the active engine (default is index_tts).`,
  };
}

const engine_help_reference = {
  index_tts: {
    display_name: "IndexTTS 2 (default)",
    summary_text:
      "High fidelity offline voice cloning with segmented inference tuned for longer scripts.",
    strengths: [
      "Great timbre matching when paired with --voice reference audio and emotion guidance.",
      "Python stack runs locally; no network or cloud calls.",
      "Supports emotion conditioning through --emo-* options for fine grained control.",
    ],
    supported_languages: [
      "English (training defaults ship with the repo)",
      "Mandarin Chinese when checkpoints include zh phoneme support",
      "Custom datasets via finetuned checkpoints for other locales",
    ],
    setup_steps: [
      "Clone the index-tts repository and run pip install -e .[inference] to provision dependencies.",
      "Place checkpoints under <repo>/checkpoints or point --index-tts-checkpoints at the location.",
      "Verify python -m index_tts.server --help runs with the selected --python-bin interpreter.",
    ],
    requirements: [
      "Requires a local index-tts checkout plus checkpoints; set --index-tts-home to help auto-detection.",
      "Demands a Python environment with torch; customize with --python-bin if auto-detect fails.",
    ],
    options: [
      engine_option_doc("index_tts", "IndexTTS"),
      shared_cli_option_docs.engine_help,
      shared_cli_option_docs.text,
      shared_cli_option_docs.text_file,
      shared_cli_option_docs.voice,
      shared_cli_option_docs.lang,
      shared_cli_option_docs.speed,
      shared_cli_option_docs.python_bin,
      shared_cli_option_docs.output,
      shared_cli_option_docs.refresh,
      shared_cli_option_docs.index_tts_home,
      shared_cli_option_docs.index_tts_checkpoints,
      shared_cli_option_docs.index_tts_config,
      shared_cli_option_docs.emo_audio,
      shared_cli_option_docs.emo_text,
      shared_cli_option_docs.emo_vector,
      shared_cli_option_docs.emo_alpha,
      shared_cli_option_docs.index_tts_fp16,
      shared_cli_option_docs.index_tts_deepspeed,
      shared_cli_option_docs.index_tts_cuda_kernel,
      shared_cli_option_docs.index_tts_random,
      shared_cli_option_docs.index_tts_max_segment,
    ],
    performance_tips: [
      "Pair --index-tts-fp16 with a GPU runtime to cut inference latency substantially.",
      "Tune --index-tts-max-segment to match GPU memory limits; smaller chunks prevent OOM events.",
      "Enable --index-tts-deepspeed for long scripts when DeepSpeed is available in the environment.",
    ],
    troubleshooting: [
      "If torch fails to import, double-check the Python environment provided via --python-bin.",
      "Gradient checkpoint errors typically mean checkpoints are mismatched—re-run git lfs pull or reseed files.",
      "Stalled generation can be resolved by deleting temporary __pycache__ directories inside the repo.",
    ],
    env_variables: [
      {
        name: "INDEX_TTS_HOME",
        description: "Override discovery of the local index-tts repository.",
      },
      {
        name: "INDEX_TTS_CHECKPOINTS",
        description:
          "Default checkpoints directory when --index-tts-checkpoints is omitted.",
      },
      {
        name: "INDEX_TTS_PYTHON",
        description:
          "Preferred Python interpreter path for shell subprocesses.",
      },
    ],
    sample_usage:
      "$0 --engine index_tts --text-file script.txt --voice speaker.wav --index-tts-home ~/git/index-tts --output out.wav",
    speaker_resolver: () => ({
      note: "IndexTTS clones any supplied reference voice; there are no preset speakers bundled with the engine.",
    }),
  },
  xtts: {
    display_name: "XTTS v2",
    summary_text:
      "Multilingual voice cloning that balances speed and quality with minimal setup compared to IndexTTS.",
    strengths: [
      "Fast startup with a Python wheel; excels for English and Chinese mixes.",
      "Supports named speaker presets via --speaker without requiring reference audio.",
      "Handles inline text or batch files with automatic language hints.",
    ],
    supported_languages: [
      "English",
      "Mandarin Chinese",
      "Japanese",
      "Korean",
      "Spanish",
      "French",
      "German",
      "Portuguese",
      "20+ additional languages via multilingual checkpoints",
    ],
    setup_steps: [
      "Install the coqui-tts xtts-v2 wheel into your Python environment.",
      "Download optional speaker preset metadata JSON if you want richer speaker discovery.",
      "Confirm xtts models load by running python -m TTS.bin.compute_embeddings --help.",
    ],
    requirements: [
      "Needs a Python environment with xtts-v2; supply --python-bin to force the interpreter.",
      "Reference voices must be short clean clips in wav/flac/ogg/mp3 when cloning.",
    ],
    options: [
      engine_option_doc("xtts", "XTTS v2"),
      shared_cli_option_docs.engine_help,
      shared_cli_option_docs.text,
      shared_cli_option_docs.text_file,
      shared_cli_option_docs.voice,
      shared_cli_option_docs.speaker,
      shared_cli_option_docs.lang,
      shared_cli_option_docs.speed,
      shared_cli_option_docs.temperature,
      shared_cli_option_docs.device,
      shared_cli_option_docs.python_bin,
      shared_cli_option_docs.output,
      shared_cli_option_docs.refresh,
    ],
    performance_tips: [
      "Set --device cuda:0 to force GPU execution when torch detects multiple adapters.",
      "Lower --temperature to 0.5 for narration that needs consistent pronunciation.",
      "Batch process files with consistent language hints to reuse cached model weights.",
    ],
    troubleshooting: [
      "Invalid voice formats usually mean the reference file is not mono PCM; re-export as 16-bit PCM WAV.",
      "If the command hangs, ensure XTTS model weights are present in the TTS cache directory.",
      "Set --debug to inspect spawned Python arguments when diagnosing interpreter paths.",
    ],
    env_variables: [
      {
        name: "XTTS_SPEAKERS_JSON",
        description: "Path to a speakers.json file used for preset discovery.",
      },
      {
        name: "XTTS_CACHE_DIR",
        description: "Custom cache directory for model downloads and metadata.",
      },
      {
        name: "XTTS_DEVICE",
        description:
          "Force a specific device override for environments without CUDA auto-detection.",
      },
    ],
    sample_usage:
      '$0 --engine xtts --text "Schedule standup for 10am" --voice ./voice.wav --output xtts.wav',
    speaker_resolver: collect_xtts_preset_speakers,
  },
  piper: {
    display_name: "Piper",
    summary_text:
      "Lightweight text-to-speech optimized for CPU usage with small ONNX models.",
    strengths: [
      "Pure Node+ONNX runtime; no Python dependency.",
      "Deterministic output ideal for scripts where voice cloning is unnecessary.",
      "Comfortable running on resource constrained machines.",
    ],
    supported_languages: [
      "Language coverage depends on the selected .onnx model",
      "Official releases include English, German, French, Spanish, Italian, and many more",
      "Mix voice models across directories to cover multiple locales in one workflow",
    ],
    setup_steps: [
      "Download a Piper .onnx voice model and matching .json config from rhasspy/piper releases.",
      "Store models together in a directory and point --piper-model at the .onnx file.",
      "Install sox or ffmpeg if you intend to post-process audio automatically.",
    ],
    requirements: [
      "Requires a compatible Piper .onnx model via --piper-model (no download is performed).",
      "Does not support cloning; choose the desired speaker baked into the model file.",
    ],
    options: [
      engine_option_doc("piper", "Piper"),
      shared_cli_option_docs.engine_help,
      shared_cli_option_docs.text,
      shared_cli_option_docs.text_file,
      shared_cli_option_docs.lang,
      shared_cli_option_docs.speed,
      shared_cli_option_docs.output,
      shared_cli_option_docs.refresh,
      shared_cli_option_docs.piper_model,
    ],
    performance_tips: [
      "Use smaller models (e.g., medium) for faster CPU inference when quality trade-offs are acceptable.",
      "Chain the output through sox tempo processing if you need more aggressive pacing adjustments.",
      "Run multiple Piper invocations in parallel when CPU cores are plentiful; models are lightweight.",
    ],
    troubleshooting: [
      "Sampling rate mismatch warnings indicate the ONNX model's sample_rate differs; convert after generation.",
      "Missing voice config files result in flat delivery—ensure the .json alongside the .onnx is accessible.",
      "If you see onnxruntime failures, reinstall onnxruntime-node with the correct CPU or GPU build.",
    ],
    env_variables: [
      {
        name: "PIPER_MODEL_DIR",
        description:
          "Directory searched when --piper-model is a bare file name.",
      },
      {
        name: "PIPER_USE_GPU",
        description:
          "Hint to prefer GPU execution when a CUDA build of onnxruntime is installed.",
      },
    ],
    sample_usage:
      '$0 --engine piper --text "All-hands starts in five." --piper-model ./en_US-amy-medium.onnx --output piper.wav',
    speaker_resolver: () => ({
      note: "Piper voices are baked into each ONNX model; swap models to change speaker characteristics.",
    }),
  },
  vibe_voice: {
    display_name: "VibeVoice",
    summary_text:
      "Diffusion-based voice generation with expressive delivery and controllable CFG guidance.",
    strengths: [
      "Expressive voices that lean toward energetic narration.",
      "Supports voice cloning with --voice similar to XTTS.",
      "CUDA and MPS acceleration available when drivers allow.",
    ],
    supported_languages: [
      "English (primary training language)",
      "Experimental support for other Latin-script languages with reference voices",
      "Requires language-conditioned finetunes for non-English best results",
    ],
    setup_steps: [
      "Download VibeVoice model weights and processor assets into a local directory tree.",
      "Install torch, torchvision, and diffusers inside the interpreter referenced by --python-bin.",
      "Verify vibe_voice.launch.py loads without errors before large batch syntheses.",
    ],
    requirements: [
      "Requires a local VibeVoice model directory; set --vibe_voice-model-dir to select it.",
      "Needs Python runtime with diffusers/torch; provide --python-bin if detection fails.",
    ],
    options: [
      engine_option_doc("vibe_voice", "VibeVoice"),
      shared_cli_option_docs.engine_help,
      shared_cli_option_docs.text,
      shared_cli_option_docs.text_file,
      shared_cli_option_docs.voice,
      shared_cli_option_docs.lang,
      shared_cli_option_docs.speed,
      shared_cli_option_docs.python_bin,
      shared_cli_option_docs.output,
      shared_cli_option_docs.refresh,
      shared_cli_option_docs.vibe_voice_model_dir,
      shared_cli_option_docs.vibe_voice_processor_dir,
      shared_cli_option_docs.vibe_voice_device,
      shared_cli_option_docs.vibe_voice_cfg_scale,
      shared_cli_option_docs.vibe_voice_max_new,
      shared_cli_option_docs.vibe_voice_ddpm_steps,
      shared_cli_option_docs.vibe_voice_half,
      shared_cli_option_docs.vibe_voice_quiet,
    ],
    performance_tips: [
      "Enable --vibe_voice-half to cut VRAM usage when running on Ampere or newer GPUs.",
      "Reduce --vibe_voice-ddpm-steps for faster drafts; increase for polished narration.",
      "Set --vibe_voice-device mps on Apple Silicon for a 2-3x speedup over CPU mode.",
    ],
    troubleshooting: [
      "Model directory layout mismatches cause missing scheduler errors—mirror the official repo structure.",
      "If CUDA kernels fail to compile, install torch==2.1.x with matching CUDA toolkit.",
      "Excessively long prompts may hit token limits; split text with --vibe_voice-max-new to constrain output size.",
    ],
    env_variables: [
      {
        name: "VIBE_VOICE_MODEL_DIR",
        description:
          "Default root searched when --vibe_voice-model-dir is omitted.",
      },
      {
        name: "VIBE_VOICE_PROCESSOR_DIR",
        description: "Override processor asset discovery without CLI flags.",
      },
      {
        name: "VIBE_VOICE_DEVICE",
        description: "System-wide hint for the preferred execution device.",
      },
    ],
    sample_usage:
      '$0 --engine vibe_voice --text "Launch the new campaign assets." --voice ./ref.wav --vibe_voice-model-dir ~/models/vibe --output vibe.wav',
    speaker_resolver: () => ({
      note: "VibeVoice requires a reference audio clip via --voice; preset catalogs are not bundled.",
    }),
  },
};

const engine_help_targets = new Set([
  ...Object.keys(engine_help_reference),
  "all",
]);

const MAX_ENGINE_HELP_SPEAKERS = Number.POSITIVE_INFINITY;

const xtts_speaker_cache = {
  scanned: false,
  labels: [],
  sources: [],
  note: null,
  language_map: {},
};

function normalize_engine_option_value(value) {
  if (value === undefined || value === null) {
    return undefined;
  }
  return String(value)
    .trim()
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, "_");
}

function prepare_cli_args_for_engine_help(raw_args) {
  const default_result = {
    cli_args: Array.isArray(raw_args) ? [...raw_args] : [],
    intercepted_help: false,
    engine_help_target: undefined,
  };

  if (!Array.isArray(raw_args) || raw_args.length === 0) {
    return default_result;
  }

  let requested_engine = null;
  let help_requested = false;

  for (let index = 0; index < raw_args.length; index += 1) {
    const token = raw_args[index];

    if (token === "--help" || token === "-h") {
      help_requested = true;
      continue;
    }

    if (token.startsWith("--engine=")) {
      requested_engine = token.slice("--engine=".length);
      continue;
    }

    if (token === "--engine" && index + 1 < raw_args.length) {
      requested_engine = raw_args[index + 1];
      index += 1;
      continue;
    }
  }

  if (!help_requested || !requested_engine) {
    return default_result;
  }

  const normalized_engine = normalize_engine_option_value(requested_engine);

  if (!normalized_engine || !engine_help_reference[normalized_engine]) {
    return default_result;
  }

  const filtered_args = raw_args.filter(
    (token) => token !== "--help" && token !== "-h",
  );

  return {
    cli_args: filtered_args,
    intercepted_help: true,
    engine_help_target: normalized_engine,
  };
}

function hide_process_argv(argv) {
  return Array.isArray(argv) ? argv.slice(2) : [];
}

(async () => {
  const { default: chalk } = await import("chalk");

  const command_name = path.basename(process.argv[1] || "text_to_speech");
  const terminal_width = Math.min(120, process.stdout.columns || 120);

  const raw_cli_args = hide_process_argv(process.argv);
  const cli_preparation = prepare_cli_args_for_engine_help(raw_cli_args);

  const parser = yargs_factory(cli_preparation.cli_args);

  parser
    .scriptName(command_name)
    .usage(
      "Usage: $0 [options] [file|glob ...]" +
        "\n\nDescription:" +
        "\n  Convert text into speech offline using IndexTTS (default), XTTS v2, Piper, or VibeVoice." +
        "\n\nTips:" +
        "\n  Use --engine <name> --help for engine-specific guidance, or --engine-help <name> directly.",
    )
    .option("engine", {
      type: "string",
      choices: ["xtts", "piper", "vibe_voice", "index_tts"],
      default: "index_tts",
      describe: "Synthesis engine to use (local only).",
    })
    .option("engine-help", {
      type: "string",
      describe:
        "Show extended documentation for an engine (index_tts|xtts|piper|vibe_voice|all) and exit.",
    })
    .option("text", {
      type: "string",
      describe: "Inline text to synthesize.",
    })
    .option("text-file", {
      type: "string",
      describe: "Path to a file containing the text to synthesize.",
    })
    .option("lang", {
      type: "string",
      choices: ["en", "zh-cn", "auto"],
      default: "en",
      describe:
        "Language code for the engine (auto defers to model heuristics).",
    })
    .option("voice", {
      type: "string",
      default: index_tts_default_voice_path,
      describe:
        "Reference speaker WAV path used by engines that support voice cloning (XTTS, VibeVoice, IndexTTS).",
    })
    .option("speaker", {
      type: "string",
      describe:
        "Named speaker preset for XTTS multi-speaker models (defaults to engine-provided voice when omitted).",
    })
    .option("output", {
      type: "string",
      describe:
        "Destination WAV file or directory (directory required for multiple inputs).",
    })
    .option("speed", {
      type: "number",
      default: 1.0,
      describe: "Playback speed multiplier (must be positive).",
    })
    .option("temperature", {
      type: "number",
      default: 0.7,
      describe: "XTTS sampling temperature (higher is more diverse).",
    })
    .option("device", {
      type: "string",
      choices: ["auto", "cpu", "cuda:0"],
      default: "auto",
      describe: "Execution device for XTTS (auto detects CUDA).",
    })
    .option("piper-model", {
      type: "string",
      describe: "Path to a Piper .onnx model (required for --engine piper).",
    })
    .option("python-bin", {
      type: "string",
      describe:
        "Explicit Python interpreter for Python-backed engines (defaults to auto-detect).",
    })
    .option("refresh", {
      type: "boolean",
      default: false,
      describe:
        "Allow overwriting existing output files (disabled by default).",
    })
    .option("index-tts-home", {
      type: "string",
      describe:
        "Path to a local index-tts checkout (auto-detects common locations when unset).",
    })
    .option("index-tts-checkpoints", {
      type: "string",
      describe:
        "Relative or absolute path to the IndexTTS checkpoints directory (defaults to <home>/checkpoints).",
    })
    .option("index-tts-config", {
      type: "string",
      describe:
        "Relative or absolute path to the IndexTTS config.yaml (defaults to <checkpoints>/config.yaml).",
    })
    .option("emo-audio", {
      type: "string",
      describe:
        "Optional emotional reference WAV used by IndexTTS for style conditioning.",
    })
    .option("emo-text", {
      type: "string",
      describe: "Optional emotion description text used by IndexTTS guidance.",
    })
    .option("emo-vector", {
      type: "string",
      describe:
        "Comma-separated or JSON array of 8 floats for explicit IndexTTS emotion control.",
    })
    .option("emo-alpha", {
      type: "number",
      default: 1.0,
      describe: "Blend strength for IndexTTS emotion conditioning (0.0-1.0).",
    })
    .option("index-tts-fp16", {
      type: "boolean",
      default: false,
      describe:
        "Enable FP16 inference for IndexTTS when the hardware supports it.",
    })
    .option("index-tts-deepspeed", {
      type: "boolean",
      default: false,
      describe:
        "Enable DeepSpeed acceleration for IndexTTS (requires extra dependencies).",
    })
    .option("index-tts-cuda-kernel", {
      type: "boolean",
      default: false,
      describe: "Allow IndexTTS to use optimized CUDA kernels when available.",
    })
    .option("index-tts-random", {
      type: "boolean",
      default: false,
      describe:
        "Enable stochastic IndexTTS sampling (may reduce cloning fidelity).",
    })
    .option("index-tts-max-segment", {
      type: "number",
      default: 120,
      describe: "Maximum text tokens per IndexTTS segment (controls chunking).",
    })
    .option("vibe_voice-model-dir", {
      type: "string",
      describe:
        "Path to a local VibeVoice model directory (defaults to VIBE_VOICE_MODEL_DIR).",
    })
    .option("vibe_voice-processor-dir", {
      type: "string",
      describe:
        "Optional override for the VibeVoice processor directory (defaults to the model dir).",
    })
    .option("vibe_voice-device", {
      type: "string",
      default: "auto",
      describe: "Execution device hint for VibeVoice (auto, cpu, cuda, mps).",
    })
    .option("vibe_voice-cfg-scale", {
      type: "number",
      default: 3.0,
      describe: "Classifier-free guidance scale for VibeVoice generation.",
    })
    .option("vibe_voice-max-new", {
      type: "number",
      describe: "Optional maximum number of tokens for VibeVoice generation.",
    })
    .option("vibe_voice-ddpm-steps", {
      type: "number",
      describe: "Optional override for VibeVoice diffusion inference steps.",
    })
    .option("vibe_voice-half", {
      type: "boolean",
      default: false,
      describe: "Run VibeVoice in half precision when supported.",
    })
    .option("vibe_voice-quiet", {
      type: "boolean",
      default: false,
      describe: "Silence VibeVoice progress output.",
    })
    .alias("h", "help")
    .example(
      '$0 --text "今天的风很舒服。This runs offline." --lang zh-cn --output out.wav',
      "Generate speech with XTTS v2 using multilingual input.",
    )
    .example(
      "$0 --speaker female-en-5 notes/*.txt",
      "Select a predefined XTTS speaker preset for batch synthesis.",
    )
    .example(
      '$0 --engine piper --text "Hello" --output en.wav --piper-model ./en_US-amy-medium.onnx',
      "Synthesize using Piper with a local English model file.",
    )
    .example(
      '$0 --engine vibe_voice --text "Team sync at 10am." --voice ./reference.wav --vibe_voice-model-dir ~/models/VibeVoice --output vibe_voice.wav',
      "Generate audio with VibeVoice using a locally downloaded model directory.",
    )
    .example(
      "$0 --engine index_tts --text-file script.txt --voice ./speaker.wav --index-tts-home ~/git/index-tts --output out.wav",
      "Clone a speaker with IndexTTS2 from a local repository checkout.",
    )
    .example(
      "$0 --engine xtts --help",
      "Display XTTS-specific help (also available via --engine-help xtts).",
    )
    .example(
      "$0 a/b/*.md c/d/*.txt",
      "Expand glob patterns, synthesize each file, and write companion WAV files.",
    );

  parser
    .wrap(terminal_width)
    .strict()
    .check((parsed) => {
      if (cli_preparation.intercepted_help) {
        parsed["engine-help"] = cli_preparation.engine_help_target;
        return true;
      }

      const engine_help_request = normalize_engine_help_input(
        parsed["engine-help"],
      );
      if (engine_help_request) {
        if (!engine_help_targets.has(engine_help_request)) {
          const supported_list = Array.from(engine_help_targets)
            .filter((item) => item !== "all")
            .sort()
            .join(", ");
          throw new Error(
            `--engine-help accepts: ${supported_list}, or 'all'.`,
          );
        }
        parsed["engine-help"] = engine_help_request;
        return true;
      }

      const has_inline_text = Boolean(parsed.text);
      const has_text_file = Boolean(parsed["text-file"]);
      const has_patterns = Array.isArray(parsed._) && parsed._.length > 0;

      const active_inputs = [
        has_inline_text,
        has_text_file,
        has_patterns,
      ].filter(Boolean).length;

      if (active_inputs === 0) {
        throw new Error(
          "Provide --text, --text-file, or one or more file/glob arguments to synthesize.",
        );
      }

      if (has_inline_text && has_text_file) {
        throw new Error(
          "Use either --text or --text-file; these options are mutually exclusive.",
        );
      }

      if (has_patterns && (has_inline_text || has_text_file)) {
        throw new Error(
          "Positional file/glob inputs cannot be combined with --text or --text-file.",
        );
      }

      if (typeof parsed.speed === "number" && parsed.speed <= 0) {
        throw new Error("--speed must be a positive number.");
      }

      if (typeof parsed.temperature === "number" && parsed.temperature <= 0) {
        throw new Error("--temperature must be greater than zero.");
      }

      return true;
    })
    .epilog(
      "Options: --engine, --engine-help, --text, --text-file, --lang, --voice, --speaker, --output, --speed, --temperature, --device, --piper-model, --python-bin, --index-tts-home, --index-tts-checkpoints, --index-tts-config, --emo-audio, --emo-text, --emo-vector, --emo-alpha, --index-tts-fp16, --index-tts-deepspeed, --index-tts-cuda-kernel, --index-tts-random, --index-tts-max-segment, --vibe_voice-model-dir, --vibe_voice-processor-dir, --vibe_voice-device, --vibe_voice-cfg-scale, --vibe_voice-max-new, --vibe_voice-ddpm-steps, --vibe_voice-half, --vibe_voice-quiet." +
        `\nExamples: ${command_name} --text 'Hello' --output hello.wav | ${command_name} --engine index_tts notes/*.txt --voice speaker.wav --index-tts-home ~/git/index-tts | ${command_name} --engine xtts --help`,
    );

  const cli_option_docs = collect_cli_option_docs(parser);

  const argv = parser.parse();

  const logger = create_logger(chalk, command_name);

  if (cli_preparation.intercepted_help) {
    render_engine_help({
      chalk,
      target: cli_preparation.engine_help_target,
      command_name,
      include_cli_tip: true,
      cli_option_docs,
    });
    return;
  }

  if (argv["engine-help"]) {
    render_engine_help({
      chalk,
      target: argv["engine-help"],
      command_name,
      cli_option_docs,
    });
    return;
  }

  let synthesis_jobs;
  try {
    synthesis_jobs = await build_synthesis_jobs(argv, logger, chalk);
  } catch (error) {
    logger.error(error?.message || String(error));
    process.exitCode = 1;
    return;
  }

  const engine_choice = argv.engine;
  const target_lang = resolve_language(engine_choice, argv.lang);
  const device_choice = argv.device || "auto";

  const voice_supported_engines = new Set(["xtts", "vibe_voice", "index_tts"]);
  if (!voice_supported_engines.has(engine_choice) && argv.voice) {
    logger.warn(
      `Ignoring --voice because it is not supported by the ${chalk.magenta(engine_choice)} engine.`,
    );
  }
  if (engine_choice !== "xtts" && argv.speaker) {
    logger.warn("Ignoring --speaker because only XTTS supports named presets.");
  }

  let xtts_voice_path = null;
  if (engine_choice === "xtts") {
    if (argv.voice) {
      xtts_voice_path = path.resolve(process.cwd(), argv.voice);
      try {
        await fs.access(xtts_voice_path);
      } catch (error) {
        throw new Error(
          `Unable to access --voice file '${xtts_voice_path}': ${error.message}`,
        );
      }

      const voice_extension = path.extname(xtts_voice_path).toLowerCase();
      if (
        voice_extension &&
        !XTTS_SUPPORTED_VOICE_EXTENSIONS.has(voice_extension)
      ) {
        const relative_voice =
          path.relative(process.cwd(), xtts_voice_path) || xtts_voice_path;
        const supported_extensions = Array.from(XTTS_SUPPORTED_VOICE_EXTENSIONS)
          .sort()
          .join(", ");
        logger.warn(
          `Ignoring --voice ${chalk.magenta(relative_voice)} because XTTS requires a reference audio file with one of the supported extensions: ${supported_extensions}. Falling back to the default speaker.`,
        );
        xtts_voice_path = null;
      }
    } else if (argv.speaker) {
      logger.info(
        `Using XTTS named speaker preset ${chalk.magenta(argv.speaker)} without cloning reference voice.`,
      );
    } else {
      logger.info(
        "No --voice or --speaker supplied; using XTTS default speaker profile.",
      );
    }
  }

  let index_tts_home_info = null;
  if (engine_choice === "index_tts") {
    try {
      index_tts_home_info = locate_index_tts_home(argv);
    } catch (error) {
      logger.error(error?.message || String(error));
      process.exitCode = 1;
      return;
    }
  }

  let python_runtime = null;
  if (["xtts", "vibe_voice", "index_tts"].includes(engine_choice)) {
    try {
      const preferred_python_bins = [];
      if (index_tts_home_info?.resolved_home) {
        const index_tts_home = index_tts_home_info.resolved_home;
        const candidate_bins = [
          path.join(index_tts_home, ".venv", "bin", "python"),
          path.join(index_tts_home, ".venv", "bin", "python3"),
          path.join(index_tts_home, ".venv", "Scripts", "python.exe"),
          path.join(index_tts_home, "venv", "bin", "python"),
          path.join(index_tts_home, "venv", "bin", "python3"),
          path.join(index_tts_home, "venv", "Scripts", "python.exe"),
        ];
        candidate_bins.forEach((candidate) => {
          if (candidate && fs_sync.existsSync(candidate)) {
            preferred_python_bins.push(candidate);
          }
        });
      }

      python_runtime = resolve_python_runtime({
        requested_bin: argv["python-bin"],
        logger,
        chalk,
        preferred_paths: preferred_python_bins,
      });
    } catch (error) {
      logger.error(error?.message || String(error));
      process.exitCode = 1;
      return;
    }
  } else if (argv["python-bin"]) {
    logger.warn(
      "Ignoring --python-bin because the Piper engine does not use a Python runtime.",
    );
  }

  let index_tts_env = null;
  if (engine_choice === "index_tts") {
    try {
      index_tts_env = resolve_index_tts_environment({
        argv,
        logger,
        chalk,
        cached_home_info: index_tts_home_info,
      });
    } catch (error) {
      logger.error(error?.message || String(error));
      process.exitCode = 1;
      return;
    }
  }

  let vibe_voice_env = null;
  if (engine_choice === "vibe_voice") {
    try {
      vibe_voice_env = resolve_vibe_voice_environment({ argv, logger, chalk });
    } catch (error) {
      logger.error(error?.message || String(error));
      process.exitCode = 1;
      return;
    }
  }

  let success_count = 0;
  let failure_count = 0;

  for (let index = 0; index < synthesis_jobs.length; index += 1) {
    const job = synthesis_jobs[index];
    const job_number = index + 1;
    const job_label = `${job.display_name}`;
    const relative_output = path.relative(process.cwd(), job.output_path);

    try {
      await fs.mkdir(path.dirname(job.output_path), { recursive: true });

      logger.info(
        `Job ${chalk.yellow(`${job_number}/${synthesis_jobs.length}`)} ${chalk.cyan(job_label)} -> ${chalk.green(relative_output)}`,
      );

      if (engine_choice === "xtts") {
        await run_xtts_engine({
          text: job.text_content,
          lang: target_lang,
          voice_path: xtts_voice_path,
          speaker: argv.speaker,
          output_path: job.output_path,
          speed: argv.speed,
          temperature: argv.temperature,
          device: device_choice,
          chalk,
          logger,
          python_bin: python_runtime.command,
        });
      } else if (engine_choice === "piper") {
        await run_piper_engine({
          text: job.text_content,
          model_path: argv["piper-model"],
          output_path: job.output_path,
          speed: argv.speed,
          temperature: argv.temperature,
          lang: target_lang,
          device: device_choice,
          chalk,
          logger,
        });
      } else if (engine_choice === "index_tts") {
        await run_index_tts_engine({
          text: job.text_content,
          output_path: job.output_path,
          env: index_tts_env,
          chalk,
          logger,
          python_bin: python_runtime.command,
        });
      } else if (engine_choice === "vibe_voice") {
        await run_vibe_voice_engine({
          text: job.text_content,
          output_path: job.output_path,
          env: vibe_voice_env,
          chalk,
          logger,
          python_bin: python_runtime.command,
        });
      } else {
        throw new Error(`Unsupported engine '${engine_choice}'.`);
      }

      success_count += 1;
    } catch (error) {
      failure_count += 1;
      logger.error(
        `Synthesis failed for ${chalk.cyan(job_label)}: ${error?.message || String(error)}`,
      );
    }
  }

  if (failure_count > 0) {
    logger.warn(
      chalk.bold.yellow(
        `Completed with ${failure_count} failure${failure_count === 1 ? "" : "s"} (${success_count} succeeded).`,
      ),
    );
    process.exitCode = 1;
  } else {
    logger.info(
      chalk.bold.green(
        `Synthesis complete (${success_count} job${success_count === 1 ? "" : "s"}).`,
      ),
    );
  }
})();

function normalize_engine_help_input(raw_value) {
  if (raw_value === undefined || raw_value === null) {
    return undefined;
  }

  if (raw_value === false) {
    return undefined;
  }

  if (raw_value === true) {
    return "all";
  }

  const normalized_text = String(raw_value).trim();
  if (normalized_text.length === 0) {
    return "all";
  }

  return normalized_text.toLowerCase().replace(/[^a-z0-9]+/g, "_");
}

function collect_xtts_preset_speakers(request = {}) {
  if (xtts_speaker_cache.scanned) {
    return {
      labels: xtts_speaker_cache.labels,
      sources: xtts_speaker_cache.sources,
      note: xtts_speaker_cache.note,
      language_map: xtts_speaker_cache.language_map,
    };
  }

  const candidate_paths = build_xtts_speaker_candidate_paths();
  const discovered = new Set();
  const sources = [];
  const languages_by_label = new Map();

  for (const candidate of candidate_paths) {
    if (!candidate) {
      continue;
    }
    let file_content;
    try {
      if (!fs_sync.existsSync(candidate)) {
        continue;
      }
      file_content = fs_sync.readFileSync(candidate, "utf8");
    } catch (error) {
      continue;
    }

    let parsed;
    try {
      parsed = JSON.parse(file_content);
    } catch (error) {
      continue;
    }

    const metadata = extract_xtts_speaker_metadata(parsed);
    if (metadata.labels.length > 0) {
      metadata.labels.forEach((label) => discovered.add(label));
      sources.push(candidate);
    }
    if (metadata.languages) {
      for (const [label, languages] of Object.entries(metadata.languages)) {
        if (!Array.isArray(languages) || languages.length === 0) {
          continue;
        }
        const normalized_label = label.trim();
        if (!normalized_label) {
          continue;
        }
        if (!languages_by_label.has(normalized_label)) {
          languages_by_label.set(normalized_label, new Map());
        }
        const store = languages_by_label.get(normalized_label);
        languages.forEach((language) => {
          const normalized_language =
            typeof language === "string" ? language.trim() : "";
          if (!normalized_language) {
            return;
          }
          const language_key = normalized_language.toLowerCase();
          if (!store.has(language_key)) {
            store.set(language_key, normalized_language);
          }
        });
      }
    }
  }

  const sorted_labels = Array.from(discovered).sort((left, right) =>
    left.localeCompare(right, undefined, { sensitivity: "base" }),
  );

  let note = null;
  if (sorted_labels.length === 0) {
    note =
      "No XTTS preset catalog was found. Download the model locally or set XTTS_SPEAKERS_JSON to point at speakers.json.";
  }

  const language_map = {};
  sorted_labels.forEach((label) => {
    const store = languages_by_label.get(label);
    if (!store || store.size === 0) {
      return;
    }
    const entries = Array.from(store.values()).sort((left, right) =>
      left.localeCompare(right, undefined, { sensitivity: "base" }),
    );
    if (entries.length > 0) {
      language_map[label] = entries;
    }
  });

  xtts_speaker_cache.scanned = true;
  xtts_speaker_cache.labels = sorted_labels;
  xtts_speaker_cache.sources = sources;
  xtts_speaker_cache.note = note;
  xtts_speaker_cache.language_map = language_map;

  return {
    labels: sorted_labels,
    sources,
    note,
    language_map,
  };
}

function build_xtts_speaker_candidate_paths() {
  const candidates = new Set();

  const direct_path = process.env.XTTS_SPEAKERS_JSON;
  if (direct_path) {
    candidates.add(path.resolve(process.cwd(), direct_path));
  }

  const indexed_home = process.env.INDEX_TTS_HOME;
  if (indexed_home) {
    const home_candidate = path.resolve(
      indexed_home,
      "checkpoints",
      "speakers.json",
    );
    candidates.add(home_candidate);
  }

  if (process.env.INDEX_TTS_CHECKPOINTS) {
    candidates.add(
      path.resolve(process.env.INDEX_TTS_CHECKPOINTS, "speakers.json"),
    );
  }

  const local_repo_candidate = path.resolve(
    __dirname,
    "../lib/tts/index_tts/checkpoints/speakers.json",
  );
  candidates.add(local_repo_candidate);

  const bundled_xtts_catalog = path.resolve(
    __dirname,
    "../lib/tts/xtts_v2/xtts_speakers.json",
  );
  candidates.add(bundled_xtts_catalog);

  const home_directory = typeof os.homedir === "function" ? os.homedir() : null;
  if (home_directory) {
    const home_candidates = [
      [
        ".local",
        "share",
        "tts",
        "tts_models",
        "multilingual",
        "multi-dataset",
        "xtts_v2",
        "speakers.json",
      ],
      [
        ".cache",
        "tts",
        "tts_models",
        "multilingual",
        "multi-dataset",
        "xtts_v2",
        "speakers.json",
      ],
      [".config", "tts", "xtts_v2", "speakers.json"],
      [
        "Library",
        "Application Support",
        "tts",
        "tts_models",
        "multilingual",
        "multi-dataset",
        "xtts_v2",
        "speakers.json",
      ],
      [
        "AppData",
        "Local",
        "tts",
        "tts_models",
        "multilingual",
        "multi-dataset",
        "xtts_v2",
        "speakers.json",
      ],
    ];

    home_candidates.forEach((segments) => {
      const absolute_path = path.join(home_directory, ...segments);
      candidates.add(absolute_path);
    });
  }

  const workspace_candidate = path.resolve(
    process.cwd(),
    "checkpoints",
    "speakers.json",
  );
  candidates.add(workspace_candidate);

  return Array.from(candidates);
}

function extract_xtts_speaker_metadata(value) {
  const collected_labels = new Set();
  const languages_by_label = new Map();

  function normalize_label_text(raw_label) {
    if (typeof raw_label !== "string") {
      return null;
    }
    const trimmed = raw_label.trim();
    if (!trimmed) {
      return null;
    }
    if (!is_probable_xtts_speaker_label(trimmed)) {
      return null;
    }
    return trimmed;
  }

  function ensure_language_store(label) {
    if (!languages_by_label.has(label)) {
      languages_by_label.set(label, new Map());
    }
    return languages_by_label.get(label);
  }

  function register_language(label, candidate) {
    const normalized_label = normalize_label_text(label);
    if (!normalized_label) {
      return;
    }
    const normalized_language = normalize_language_token(candidate);
    if (!normalized_language) {
      return;
    }
    const language_key = normalized_language.toLowerCase();
    const store = ensure_language_store(normalized_label);
    if (!store.has(language_key)) {
      store.set(language_key, normalized_language);
    }
  }

  function collect_language_candidates_from_object(
    node,
    existing_languages = [],
  ) {
    if (!node || typeof node !== "object") {
      return existing_languages;
    }

    const accumulator = new Map();
    existing_languages.forEach((entry) => {
      if (typeof entry === "string" && entry) {
        accumulator.set(entry.toLowerCase(), entry);
      }
    });

    for (const [key, entry] of Object.entries(node)) {
      if (!key) {
        continue;
      }
      const lower_key = key.toLowerCase();
      if (lower_key.includes("lang")) {
        gather_language_values(entry, accumulator);
        continue;
      }
      if (is_probable_language_code(key)) {
        gather_language_values(key, accumulator);
        gather_language_values(entry, accumulator);
      }
    }

    return Array.from(accumulator.values());
  }

  function gather_language_values(value, accumulator) {
    if (!accumulator || value === undefined || value === null) {
      return;
    }
    if (typeof value === "string" || typeof value === "number") {
      const normalized = normalize_language_token(value);
      if (!normalized) {
        return;
      }
      const key = normalized.toLowerCase();
      if (!accumulator.has(key)) {
        accumulator.set(key, normalized);
      }
      return;
    }
    if (Array.isArray(value)) {
      value.forEach((entry) => gather_language_values(entry, accumulator));
      return;
    }
    if (typeof value === "object") {
      for (const [key, entry] of Object.entries(value)) {
        if (is_probable_language_code(key)) {
          gather_language_values(key, accumulator);
        }
        gather_language_values(entry, accumulator);
      }
    }
  }

  function add_label(label, default_languages = []) {
    const normalized_label = normalize_label_text(label);
    if (!normalized_label) {
      return;
    }
    collected_labels.add(normalized_label);
    if (Array.isArray(default_languages) && default_languages.length > 0) {
      default_languages.forEach((lang) =>
        register_language(normalized_label, lang),
      );
    }
  }

  function extract_label_from_object(node) {
    if (!node || typeof node !== "object") {
      return null;
    }
    const candidate_fields = [
      "name",
      "speaker",
      "voice",
      "label",
      "title",
      "id",
    ];
    for (const field of candidate_fields) {
      const candidate = node[field];
      if (typeof candidate === "string") {
        const normalized = normalize_label_text(candidate);
        if (normalized) {
          return normalized;
        }
      }
    }
    return null;
  }

  function process_node(node, inherited_languages = []) {
    if (!node) {
      return;
    }

    if (typeof node === "string" || typeof node === "number") {
      add_label(String(node), inherited_languages);
      return;
    }

    if (Array.isArray(node)) {
      node.forEach((entry) => process_node(entry, inherited_languages));
      return;
    }

    if (typeof node === "object") {
      const entries = Object.entries(node);
      let handled_language_groups = false;

      for (const [key, entry] of entries) {
        if (is_probable_language_code(key)) {
          handled_language_groups = true;
          const normalized_language = normalize_language_token(key);
          const language_list = normalized_language
            ? [normalized_language]
            : [];
          process_node(entry, language_list);
        }
      }

      if (handled_language_groups) {
        return;
      }

      const accumulator = new Map();
      const inherited_array = Array.isArray(inherited_languages)
        ? inherited_languages.filter(
            (value) => typeof value === "string" && value.trim(),
          )
        : [];

      inherited_array.forEach((value) => {
        const normalized_language =
          normalize_language_token(value) || String(value).trim();
        if (normalized_language) {
          accumulator.set(
            normalized_language.toLowerCase(),
            normalized_language,
          );
        }
      });

      entries.forEach(([key, entry]) => {
        if (typeof key === "string" && key.toLowerCase().includes("lang")) {
          gather_language_values(entry, accumulator);
        }
      });

      const merged_languages = Array.from(accumulator.values());

      for (const [key, entry] of entries) {
        const lower_key = typeof key === "string" ? key.toLowerCase() : "";

        if (lower_key.includes("lang")) {
          process_node(entry, merged_languages);
          continue;
        }

        const normalized_key_label = normalize_label_text(key);
        if (normalized_key_label) {
          const explicit_languages = collect_language_candidates_from_object(
            entry,
            merged_languages,
          );
          const language_list =
            explicit_languages.length > 0
              ? explicit_languages
              : merged_languages;
          add_label(normalized_key_label, language_list);
          process_node(entry, language_list);
          continue;
        }

        if (typeof entry === "string" || typeof entry === "number") {
          add_label(entry, merged_languages);
          continue;
        }

        if (Array.isArray(entry)) {
          process_node(entry, merged_languages);
          continue;
        }

        if (typeof entry === "object") {
          const label_from_fields = extract_label_from_object(entry);
          const explicit_languages = collect_language_candidates_from_object(
            entry,
            merged_languages,
          );
          const language_list =
            explicit_languages.length > 0
              ? explicit_languages
              : merged_languages;

          if (label_from_fields) {
            add_label(label_from_fields, language_list);
          }

          process_node(entry, language_list);
        }
      }
    }
  }

  process_node(value, []);

  const serialized_languages = {};
  for (const [label, store] of languages_by_label.entries()) {
    if (!store || store.size === 0) {
      continue;
    }
    serialized_languages[label] = Array.from(store.values()).sort(
      (left, right) =>
        left.localeCompare(right, undefined, { sensitivity: "base" }),
    );
  }

  return {
    labels: Array.from(collected_labels),
    languages: serialized_languages,
  };
}

const LANGUAGE_CODE_REGEX = /^[a-z]{2,3}(?:[-_][a-z0-9]{2,8})*$/i;

function is_probable_language_code(value) {
  if (typeof value !== "string") {
    return false;
  }
  return LANGUAGE_CODE_REGEX.test(value.trim());
}

function normalize_language_token(value) {
  if (value === undefined || value === null) {
    return null;
  }
  const text = String(value).trim();
  if (!text) {
    return null;
  }
  if (!LANGUAGE_CODE_REGEX.test(text)) {
    return null;
  }
  return text.toLowerCase().replace(/_/g, "-");
}

function is_probable_xtts_speaker_label(value) {
  if (typeof value !== "string") {
    return false;
  }
  const trimmed = value.trim();
  if (!trimmed) {
    return false;
  }
  if (trimmed.length > 64) {
    return false;
  }
  if (/[\\/]/.test(trimmed)) {
    return false;
  }
  if (/\.(wav|mp3|flac|ogg|pt|pth|json|yaml|yml)$/i.test(trimmed)) {
    return false;
  }
  if (is_probable_language_code(trimmed)) {
    return false;
  }
  if (!/[a-z]/i.test(trimmed)) {
    return false;
  }
  return true;
}

function render_engine_help({
  chalk,
  target,
  command_name,
  include_cli_tip = false,
  cli_option_docs = [],
}) {
  const resolved_target =
    target === "all" ? Object.keys(engine_help_reference) : [target];

  const separator_line = chalk.gray("-".repeat(terminal_width_for_help()));

  resolved_target.forEach((engine_key, index) => {
    const spec = engine_help_reference[engine_key];
    if (!spec) {
      return;
    }

    if (index > 0) {
      console.log("\n" + separator_line);
    }

    const heading = `${chalk.bold.magenta(spec.display_name)} ${chalk.gray(`(${engine_key})`)}`;
    console.log(heading);
    console.log(chalk.white(spec.summary_text));

    const speaker_info =
      typeof spec.speaker_resolver === "function"
        ? spec.speaker_resolver({ resolve_full_list: true })
        : null;

    if (spec.strengths && spec.strengths.length > 0) {
      console.log(`\n${chalk.cyan("Highlights:")}`);
      spec.strengths.forEach((line) => {
        console.log(`  - ${line}`);
      });
    }

    if (spec.supported_languages && spec.supported_languages.length > 0) {
      const languages_text = spec.supported_languages
        .map((entry) => (typeof entry === "string" ? entry.trim() : ""))
        .filter((entry) => entry.length > 0)
        .join(", ");
      if (languages_text) {
        console.log(
          `\n${chalk.cyanBright("Supported languages:")} ${languages_text}`,
        );
      }
    }

    if (spec.setup_steps && spec.setup_steps.length > 0) {
      console.log(`\n${chalk.magenta("Setup checklist:")}`);
      spec.setup_steps.forEach((line) => {
        console.log(`  - ${line}`);
      });
    }

    if (spec.requirements && spec.requirements.length > 0) {
      console.log(`\n${chalk.yellow("Requirements:")}`);
      spec.requirements.forEach((line) => {
        console.log(`  - ${line}`);
      });
    }

    const option_entries = spec.options || spec.notable_flags;
    if (option_entries && option_entries.length > 0) {
      console.log(`\n${chalk.green("Options:")}`);
      option_entries.forEach((entry) => {
        console.log(`  - ${chalk.bold(entry.flag)}: ${entry.description}`);
      });
    }

    if (spec.performance_tips && spec.performance_tips.length > 0) {
      console.log(`\n${chalk.blueBright("Performance notes:")}`);
      spec.performance_tips.forEach((line) => {
        console.log(`  - ${line}`);
      });
    }

    if (spec.env_variables && spec.env_variables.length > 0) {
      console.log(`\n${chalk.yellowBright("Environment variables:")}`);
      spec.env_variables.forEach((entry) => {
        if (entry && entry.name && entry.description) {
          console.log(`  - ${chalk.bold(entry.name)}: ${entry.description}`);
        } else if (typeof entry === "string") {
          console.log(`  - ${entry}`);
        }
      });
    }

    if (spec.troubleshooting && spec.troubleshooting.length > 0) {
      console.log(`\n${chalk.red("Troubleshooting:")}`);
      spec.troubleshooting.forEach((line) => {
        console.log(`  - ${line}`);
      });
    }

    if (spec.sample_usage) {
      console.log(`\n${chalk.blue("Example:")}`);
      console.log(`  ${chalk.gray("# Suggested invocation")}`);
      const rendered_sample = spec.sample_usage.split("$0").join(command_name);
      console.log(`  ${rendered_sample}`);
    }

    if (speaker_info) {
      if (
        Array.isArray(speaker_info.labels) &&
        speaker_info.labels.length > 0
      ) {
        console.log(`\n${chalk.magentaBright("Speakers:")}`);
        const displayed = speaker_info.labels.slice(
          0,
          MAX_ENGINE_HELP_SPEAKERS,
        );
        const languages_for_speakers =
          speaker_info.language_map &&
          typeof speaker_info.language_map === "object"
            ? speaker_info.language_map
            : {};
        const speaker_lines = displayed.map((label) => {
          const languages = Array.isArray(languages_for_speakers[label])
            ? languages_for_speakers[label].filter(
                (entry) => typeof entry === "string" && entry.trim(),
              )
            : [];
          if (languages.length > 0) {
            return `${label} (${languages.join(", ")})`;
          }
          return label;
        });
        if (speaker_lines.length > 0) {
          console.log(`  ${speaker_lines.join(", ")}`);
        }
        if (speaker_info.labels.length > MAX_ENGINE_HELP_SPEAKERS) {
          const remaining =
            speaker_info.labels.length - MAX_ENGINE_HELP_SPEAKERS;
          console.log(
            `  ${chalk.gray(`Additional speakers available (${remaining} more). Set XTTS_SPEAKERS_JSON to inspect full list.`)}`,
          );
        }
        if (
          Array.isArray(speaker_info.sources) &&
          speaker_info.sources.length > 0
        ) {
          const primary_source = speaker_info.sources[0];
          const extra_sources = speaker_info.sources.length - 1;
          const source_suffix =
            extra_sources > 0 ? ` (+${extra_sources} alt)` : "";
          console.log(
            `  ${chalk.gray(`Source: ${path.relative(process.cwd(), primary_source) || primary_source}${source_suffix}`)}`,
          );
        }
      } else if (speaker_info.note) {
        console.log(
          `\n${chalk.magentaBright("Speakers:")} ${chalk.gray(speaker_info.note)}`,
        );
      }
    }
  });

  console.log(
    "\n" + chalk.gray("Use --engine to select the engine for synthesis."),
  );
  if (include_cli_tip) {
    console.log(
      chalk.gray(
        `Run ${command_name} --help to view global CLI options and examples.`,
      ),
    );
  }

  if (Array.isArray(cli_option_docs) && cli_option_docs.length > 0) {
    console.log(`\n${chalk.gray("Complete CLI options:")}`);
    cli_option_docs.forEach((entry) => {
      const segments = [chalk.bold(entry.flag)];
      if (entry.aliases && entry.aliases.length > 0) {
        segments.push(chalk.gray(`[aliases: ${entry.aliases.join(", ")}]`));
      }
      if (entry.type) {
        segments.push(chalk.gray(`[type: ${entry.type}]`));
      }
      if (entry.choices && entry.choices.length > 0) {
        segments.push(chalk.gray(`[choices: ${entry.choices.join(", ")}]`));
      }
      if (entry.default_value !== undefined) {
        segments.push(chalk.gray(`[default: ${entry.default_value}]`));
      }
      const description_suffix = entry.description
        ? ` — ${entry.description}`
        : "";
      console.log(`  - ${segments.join(" ")}${description_suffix}`);
    });
  }
}

function collect_cli_option_docs(parser) {
  if (!parser || typeof parser.getOptions !== "function") {
    return [];
  }

  const options = parser.getOptions();
  const keys = Object.keys(options?.key || {});
  const seen_flags = new Set();
  const docs = [];

  keys.forEach((name) => {
    if (should_skip_option_doc(name, options)) {
      return;
    }
    const type = detect_option_type(name, options);
    const flag = format_option_flag(name, type);
    if (seen_flags.has(flag)) {
      return;
    }
    const aliases = normalize_option_aliases(name, options?.alias);
    const choices = Array.isArray(options?.choices?.[name])
      ? options.choices[name].map((choice) => `${choice}`)
      : [];
    const default_value = options?.default?.[name];
    const description = options?.describe?.[name] || "";

    docs.push({
      flag,
      type,
      aliases,
      choices,
      default_value,
      description,
      original_name: name,
    });
    seen_flags.add(flag);
  });

  return docs.sort((left, right) =>
    left.flag.localeCompare(right.flag, undefined, { sensitivity: "base" }),
  );
}

function detect_option_type(name, options) {
  const candidate_lists = [
    { label: "boolean", items: options?.boolean },
    { label: "number", items: options?.number },
    { label: "string", items: options?.string },
    { label: "array", items: options?.array },
  ];

  for (const candidate of candidate_lists) {
    if (Array.isArray(candidate.items) && candidate.items.includes(name)) {
      return candidate.label;
    }
  }

  return null;
}

function format_option_flag(name, type) {
  const prefix = name.length === 1 ? "-" : "--";
  if (type && type !== "boolean") {
    return `${prefix}${name} <${type}>`;
  }
  return `${prefix}${name}`;
}

function normalize_option_aliases(name, alias_map) {
  if (!alias_map) {
    return [];
  }
  const raw_aliases = alias_map[name];
  if (!raw_aliases) {
    return [];
  }
  const entries = Array.isArray(raw_aliases) ? raw_aliases : [raw_aliases];
  const normalized = new Set();
  entries.forEach((entry) => {
    if (typeof entry !== "string") {
      return;
    }
    const trimmed = entry.trim();
    if (!trimmed || trimmed === name) {
      return;
    }
    const prefix = trimmed.length === 1 ? "-" : "--";
    normalized.add(`${prefix}${trimmed}`);
  });
  return Array.from(normalized).sort((left, right) =>
    left.localeCompare(right, undefined, { sensitivity: "base" }),
  );
}

function should_skip_option_doc(name, options) {
  const alias_entries = options?.alias?.[name];
  if (
    typeof name === "string" &&
    name.length === 1 &&
    Array.isArray(alias_entries) &&
    alias_entries.some((alias) => typeof alias === "string" && alias.length > 1)
  ) {
    return true;
  }
  return false;
}

function terminal_width_for_help() {
  const default_width = 80;
  if (
    typeof process.stdout.columns === "number" &&
    process.stdout.columns > 0
  ) {
    return Math.min(120, process.stdout.columns);
  }
  return default_width;
}

function create_logger(chalk, command_name) {
  const label_info = chalk.bold.blue("INFO");
  const label_warn = chalk.bold.yellow("WARN");
  const label_error = chalk.bold.red("ERROR");
  const label_verbose = chalk.bold.gray("DETAIL");

  return {
    info(message) {
      console.log(`${label_info} ${chalk.cyan(command_name)} ${message}`);
    },
    warn(message) {
      console.warn(`${label_warn} ${chalk.cyan(command_name)} ${message}`);
    },
    error(message) {
      console.error(`${label_error} ${chalk.cyan(command_name)} ${message}`);
    },
    verbose(message) {
      console.log(`${label_verbose} ${chalk.cyan(command_name)} ${message}`);
    },
  };
}

async function build_synthesis_jobs(argv, logger, chalk) {
  if (argv.text) {
    const trimmed_inline = String(argv.text).trim();
    if (!trimmed_inline) {
      throw new Error("Inline --text is empty after trimming.");
    }
    return finalize_jobs(
      [
        {
          text_content: trimmed_inline,
          source_file: null,
          display_name: "inline-text",
        },
      ],
      argv,
      logger,
      chalk,
    );
  }

  if (argv["text-file"]) {
    const absolute_path = path.resolve(process.cwd(), argv["text-file"]);
    const file_job = await create_job_from_file(absolute_path);
    return finalize_jobs([file_job], argv, logger, chalk);
  }

  const patterns = Array.isArray(argv._) ? argv._ : [];
  const expanded_files = expand_patterns(patterns, { cwd: process.cwd() });

  if (expanded_files.length === 0) {
    throw new Error("No files matched the provided patterns.");
  }

  const file_jobs = [];
  for (const absolute_file_path of expanded_files) {
    const job = await create_job_from_file(absolute_file_path);
    file_jobs.push(job);
  }

  return finalize_jobs(file_jobs, argv, logger, chalk);
}

async function create_job_from_file(absolute_file_path) {
  let file_content;
  try {
    file_content = await fs.readFile(absolute_file_path, "utf8");
  } catch (error) {
    throw new Error(
      `Unable to read text file '${absolute_file_path}': ${error.message}`,
    );
  }

  const trimmed_content = file_content.trim();
  if (!trimmed_content) {
    throw new Error(
      `Text file '${absolute_file_path}' has no readable content.`,
    );
  }

  const relative_path =
    path.relative(process.cwd(), absolute_file_path) ||
    path.basename(absolute_file_path);

  return {
    text_content: trimmed_content,
    source_file: absolute_file_path,
    display_name: relative_path,
  };
}

async function finalize_jobs(jobs, argv, logger, chalk) {
  if (!Array.isArray(jobs) || jobs.length === 0) {
    throw new Error("No synthesis jobs were produced.");
  }

  const output_override = argv.output
    ? path.resolve(process.cwd(), argv.output)
    : null;

  let output_directory = null;
  let explicit_output_file = null;

  if (output_override) {
    let output_stats = null;
    try {
      output_stats = await fs.stat(output_override);
    } catch (error) {
      if (error && error.code === "ENOENT") {
        if (jobs.length > 1) {
          output_directory = output_override;
        } else {
          explicit_output_file = output_override;
        }
      } else {
        throw new Error(
          `Unable to access output path '${output_override}': ${error.message}`,
        );
      }
    }

    if (output_stats) {
      if (output_stats.isDirectory()) {
        output_directory = output_override;
      } else {
        if (jobs.length > 1) {
          throw new Error(
            "--output must point to a directory when synthesizing multiple inputs.",
          );
        }
        explicit_output_file = output_override;
      }
    }
  }

  if (output_directory) {
    await fs.mkdir(output_directory, { recursive: true });
  }

  const viable_jobs = [];
  let skipped_count = 0;

  for (let index = 0; index < jobs.length; index += 1) {
    const job = jobs[index];

    if (explicit_output_file) {
      job.output_path = explicit_output_file;
    } else if (output_directory) {
      const base_name = job.source_file
        ? path.parse(job.source_file).name
        : `inline_${String(index + 1)
            .toString()
            .padStart(2, "0")}`;
      job.output_path = path.join(output_directory, `${base_name}.wav`);
    } else if (job.source_file) {
      const parsed_source = path.parse(job.source_file);
      job.output_path = path.join(
        parsed_source.dir,
        `${parsed_source.name}.wav`,
      );
    } else {
      job.output_path = path.resolve(
        process.cwd(),
        argv.output || "text_to_speech_output.wav",
      );
    }

    if (!argv.refresh) {
      try {
        await fs.access(job.output_path);

        const relative_output =
          path.relative(process.cwd(), job.output_path) || job.output_path;

        logger.verbose(
          `${chalk.gray("Skipping existing output")} ${chalk.green(relative_output)} ${chalk.gray("(use --refresh to overwrite).")}`,
        );

        skipped_count += 1;
        continue;
      } catch (error) {
        if (!error || error.code !== "ENOENT") {
          throw error;
        }
      }
    }

    const plain_text_content = convert_markdown_to_plain_text(job.text_content);
    if (!plain_text_content) {
      const text_label = job.display_name || job.source_file || "input";
      throw new Error(
        `Input '${text_label}' has no readable text after Markdown conversion.`,
      );
    }

    job.text_content = plain_text_content;

    viable_jobs.push(job);
  }

  if (skipped_count > 0 && viable_jobs.length === 0) {
    logger.info(
      chalk.yellow(
        "All requested outputs already exist; nothing to synthesize. Run with --refresh to regenerate audio.",
      ),
    );
  } else if (skipped_count > 0) {
    logger.info(
      chalk.yellow(
        `${skipped_count} existing output${skipped_count === 1 ? " was" : "s were"} skipped (use --refresh to overwrite).`,
      ),
    );
  }

  return viable_jobs;
}

function locate_index_tts_home(argv) {
  const cwd = process.cwd();
  const explicit_hint = argv["index-tts-home"] || process.env.INDEX_TTS_HOME;

  if (explicit_hint) {
    const resolved_explicit = path.resolve(cwd, explicit_hint);
    let explicit_stats;
    try {
      explicit_stats = fs_sync.statSync(resolved_explicit);
    } catch (error) {
      throw new Error(
        `IndexTTS home '${resolved_explicit}' is not accessible: ${error.message}`,
      );
    }

    if (!explicit_stats.isDirectory()) {
      throw new Error(
        `IndexTTS home '${resolved_explicit}' is not a directory.`,
      );
    }

    return {
      resolved_home: resolved_explicit,
      auto_detected: false,
      fallback_paths: [],
    };
  }

  const fallback_paths = [
    path.join(os.homedir(), "code_base", "index_tts"),
    path.join(os.homedir(), "code_base", "index-tts"),
    path.join(os.homedir(), "index_tts"),
    path.join(os.homedir(), "index-tts"),
    path.join(cwd, "index_tts"),
    path.join(cwd, "index-tts"),
  ];

  for (const candidate_path of fallback_paths) {
    try {
      const candidate_stats = fs_sync.statSync(candidate_path);
      if (candidate_stats.isDirectory()) {
        return {
          resolved_home: candidate_path,
          auto_detected: true,
          fallback_paths,
        };
      }
    } catch (error) {
      // Ignore missing paths and continue searching.
      continue;
    }
  }

  return {
    resolved_home: null,
    auto_detected: false,
    fallback_paths,
  };
}

function resolve_index_tts_environment({
  argv,
  logger,
  chalk,
  cached_home_info = null,
}) {
  const cwd = process.cwd();
  const home_info = cached_home_info || locate_index_tts_home(argv);
  const { resolved_home, auto_detected, fallback_paths } = home_info;

  if (!resolved_home) {
    const searched_targets = fallback_paths
      .map((candidate_path) => {
        const relative_path = path.relative(cwd, candidate_path);
        return relative_path.startsWith(".") ? candidate_path : relative_path;
      })
      .join(", ");

    throw new Error(
      `IndexTTS requires --index-tts-home or INDEX_TTS_HOME to point to a local checkout. Checked: ${searched_targets}.`,
    );
  }

  const checkpoints_hint = argv["index-tts-checkpoints"] || "checkpoints";
  const resolved_checkpoints = path.isAbsolute(checkpoints_hint)
    ? checkpoints_hint
    : path.resolve(resolved_home, checkpoints_hint);
  if (!fs_sync.existsSync(resolved_checkpoints)) {
    throw new Error(
      `IndexTTS checkpoints not found at '${resolved_checkpoints}'. Use --index-tts-checkpoints to override.`,
    );
  }

  const config_hint = argv["index-tts-config"];
  const resolved_config = config_hint
    ? path.resolve(
        path.isAbsolute(config_hint)
          ? config_hint
          : path.join(resolved_home, config_hint),
      )
    : path.join(resolved_checkpoints, "config.yaml");

  if (!fs_sync.existsSync(resolved_config)) {
    throw new Error(
      `IndexTTS config not found at '${resolved_config}'. Provide --index-tts-config when using custom layouts.`,
    );
  }

  let voice_path = null;
  if (argv.voice) {
    voice_path = path.resolve(cwd, argv.voice);
  }
  if (!voice_path) {
    const default_voice = path.join(resolved_home, "examples", "voice_01.wav");
    if (fs_sync.existsSync(default_voice)) {
      voice_path = default_voice;
    }
  }
  if (!voice_path || !fs_sync.existsSync(voice_path)) {
    throw new Error(
      "IndexTTS requires a speaker reference WAV. Provide --voice or place examples/voice_01.wav in the checkout.",
    );
  }

  let emo_audio_path = null;
  if (argv["emo-audio"]) {
    emo_audio_path = path.resolve(cwd, argv["emo-audio"]);
    if (!fs_sync.existsSync(emo_audio_path)) {
      throw new Error(
        `Emotion reference audio not found at '${emo_audio_path}'.`,
      );
    }
  }

  let emo_vector = null;
  if (argv["emo-vector"]) {
    try {
      emo_vector = parse_emo_vector_option(argv["emo-vector"]);
    } catch (error) {
      throw new Error(error.message);
    }
  }

  const emo_text =
    typeof argv["emo-text"] === "string" && argv["emo-text"].trim()
      ? argv["emo-text"].trim()
      : null;

  const emo_alpha =
    typeof argv["emo-alpha"] === "number" ? argv["emo-alpha"] : 1.0;
  if (!Number.isFinite(emo_alpha) || emo_alpha < 0 || emo_alpha > 1) {
    throw new Error("--emo-alpha must be a number between 0.0 and 1.0.");
  }

  const max_text_segment = Number.isFinite(argv["index-tts-max-segment"])
    ? argv["index-tts-max-segment"]
    : 120;
  if (max_text_segment <= 0) {
    throw new Error("--index-tts-max-segment must be a positive integer.");
  }

  const python_path_entries = new Set();
  python_path_entries.add(resolved_home);
  const module_dirs = ["indextts", "src"];
  module_dirs.forEach((dir_name) => {
    const candidate = path.join(resolved_home, dir_name);
    if (fs_sync.existsSync(candidate)) {
      python_path_entries.add(candidate);
    }
  });

  const hf_cache = path.join(resolved_checkpoints, "hf_cache");

  if (auto_detected) {
    const home_label = path.relative(cwd, resolved_home) || resolved_home;
    logger.info(
      `Auto-detected IndexTTS home at ${chalk.magenta(home_label)}. Override via --index-tts-home when needed.`,
    );
  }

  logger.info(
    `IndexTTS home ${chalk.magenta(path.relative(cwd, resolved_home) || resolved_home)}; checkpoints ${chalk.magenta(path.relative(cwd, resolved_checkpoints) || resolved_checkpoints)}`,
  );

  return {
    home_path: resolved_home,
    checkpoints_path: resolved_checkpoints,
    config_path: resolved_config,
    voice_path,
    emo_audio_path,
    emo_vector,
    emo_text,
    emo_alpha,
    use_random: Boolean(argv["index-tts-random"]),
    use_fp16: Boolean(argv["index-tts-fp16"]),
    use_deepspeed: Boolean(argv["index-tts-deepspeed"]),
    use_cuda_kernel: Boolean(argv["index-tts-cuda-kernel"]),
    max_text_segment,
    python_path: Array.from(python_path_entries),
    hf_cache_path: hf_cache,
  };
}

function resolve_vibe_voice_environment({ argv, logger, chalk }) {
  const cwd = process.cwd();
  const model_hint =
    argv["vibe_voice-model-dir"] || process.env.VIBE_VOICE_MODEL_DIR;
  if (!model_hint) {
    throw new Error(
      "VibeVoice requires --vibe_voice-model-dir or VIBE_VOICE_MODEL_DIR to point to downloaded weights.",
    );
  }

  const model_dir = path.resolve(cwd, model_hint);
  if (!fs_sync.existsSync(model_dir)) {
    throw new Error(`VibeVoice model directory '${model_dir}' does not exist.`);
  }

  const processor_hint = argv["vibe_voice-processor-dir"];
  const processor_dir = processor_hint
    ? path.resolve(
        path.isAbsolute(processor_hint)
          ? processor_hint
          : path.join(model_dir, processor_hint),
      )
    : model_dir;
  if (!fs_sync.existsSync(processor_dir)) {
    throw new Error(
      `VibeVoice processor directory '${processor_dir}' does not exist.`,
    );
  }

  if (!argv.voice) {
    throw new Error(
      "VibeVoice requires --voice to supply at least one reference sample.",
    );
  }
  const voice_path = path.resolve(cwd, argv.voice);
  if (!fs_sync.existsSync(voice_path)) {
    throw new Error(
      `Unable to access VibeVoice reference audio '${voice_path}'.`,
    );
  }

  const device_hint = argv["vibe_voice-device"] || "auto";

  const cfg_scale =
    typeof argv["vibe_voice-cfg-scale"] === "number"
      ? argv["vibe_voice-cfg-scale"]
      : 3.0;
  if (!Number.isFinite(cfg_scale) || cfg_scale <= 0) {
    throw new Error("--vibe_voice-cfg-scale must be a positive number.");
  }

  const max_new_tokens =
    typeof argv["vibe_voice-max-new"] === "number"
      ? argv["vibe_voice-max-new"]
      : null;
  if (max_new_tokens !== null && max_new_tokens <= 0) {
    throw new Error(
      "--vibe_voice-max-new must be greater than zero when provided.",
    );
  }

  const ddpm_steps =
    typeof argv["vibe_voice-ddpm-steps"] === "number"
      ? argv["vibe_voice-ddpm-steps"]
      : null;
  if (ddpm_steps !== null && ddpm_steps <= 0) {
    throw new Error(
      "--vibe_voice-ddpm-steps must be greater than zero when provided.",
    );
  }

  logger.info(
    `VibeVoice model dir ${chalk.magenta(path.relative(cwd, model_dir) || model_dir)}; processor ${chalk.magenta(path.relative(cwd, processor_dir) || processor_dir)}`,
  );

  return {
    model_dir,
    processor_dir,
    voice_path,
    device_hint,
    cfg_scale,
    max_new_tokens,
    ddpm_steps,
    use_half: Boolean(argv["vibe_voice-half"]),
    quiet: Boolean(argv["vibe_voice-quiet"]),
  };
}

function parse_emo_vector_option(raw_value) {
  const trimmed = String(raw_value || "").trim();
  if (!trimmed) {
    return null;
  }

  let parsed;
  try {
    parsed = JSON.parse(trimmed);
  } catch (error) {
    parsed = trimmed
      .split(/[,\s]+/)
      .map((token) => token.trim())
      .filter(Boolean);
  }

  if (!Array.isArray(parsed)) {
    throw new Error(
      "--emo-vector must be a JSON array or comma separated list of numbers.",
    );
  }

  const floats = parsed.map((value) => Number(value));
  if (floats.some((value) => !Number.isFinite(value))) {
    throw new Error("--emo-vector contains non-numeric entries.");
  }

  if (floats.length !== 8) {
    throw new Error("--emo-vector must contain exactly 8 numeric entries.");
  }

  return floats;
}

function resolve_language(engine, requested_lang) {
  if (engine === "piper") {
    return requested_lang;
  }

  const normalized = (requested_lang || "en").toLowerCase();
  const supported_langs = {
    en: "en",
    "zh-cn": "zh-cn",
    auto: "auto",
  };

  if (!supported_langs[normalized]) {
    return "en";
  }

  return supported_langs[normalized];
}

async function run_xtts_engine({
  text,
  lang,
  voice_path,
  speaker,
  output_path,
  speed,
  temperature,
  device,
  chalk,
  logger,
  python_bin,
}) {
  const engine_script_path = path.resolve(
    __dirname,
    "..",
    "lib",
    "index_tts",
    "engines",
    "xtts_local.py",
  );

  const args = [
    engine_script_path,
    "--text",
    text,
    "--out",
    output_path,
    "--lang",
    lang,
    "--speed",
    String(speed),
    "--temperature",
    String(temperature),
    "--device",
    device,
  ];

  if (voice_path) {
    args.push("--voice", voice_path);
  }

  if (speaker) {
    args.push("--speaker", speaker);
  }

  logger.info(`Running XTTS via ${chalk.gray(python_bin)}.`);

  const child_env = { ...process.env, COQUI_TOS_AGREED: "1" };

  await run_child_process(python_bin, args, {
    cwd: process.cwd(),
    env: child_env,
    chalk,
    label: "XTTS",
  });
}

async function run_index_tts_engine({
  text,
  output_path,
  env,
  chalk,
  logger,
  python_bin,
}) {
  const script_path = path.resolve(
    __dirname,
    "..",
    "lib",
    "index_tts",
    "engines",
    "index_tts_local.py",
  );

  const args = [
    script_path,
    "--text",
    text,
    "--out",
    output_path,
    "--home",
    env.home_path,
    "--checkpoints",
    env.checkpoints_path,
    "--config",
    env.config_path,
    "--voice",
    env.voice_path,
    "--emo-alpha",
    String(env.emo_alpha ?? 1),
    "--max-text-segment",
    String(env.max_text_segment),
  ];

  if (env.emo_audio_path) {
    args.push("--emo-audio", env.emo_audio_path);
  }
  if (env.emo_text) {
    args.push("--emo-text", env.emo_text);
  }
  if (Array.isArray(env.emo_vector)) {
    args.push("--emo-vector", JSON.stringify(env.emo_vector));
  }
  if (env.use_random) {
    args.push("--use-random");
  }
  if (env.use_fp16) {
    args.push("--use-fp16");
  }
  if (env.use_deepspeed) {
    args.push("--use-deepspeed");
  }
  if (env.use_cuda_kernel) {
    args.push("--use-cuda-kernel");
  }

  const child_env = { ...process.env };
  child_env.INDEX_TTS_HOME = env.home_path;
  child_env.INDEX_TTS_CHECKPOINTS = env.checkpoints_path;
  child_env.INDEX_TTS_CONFIG = env.config_path;
  child_env.HF_HOME = env.hf_cache_path;
  child_env.HF_HUB_CACHE = env.hf_cache_path;
  child_env.HUGGINGFACE_HUB_CACHE = env.hf_cache_path;
  child_env.TRANSFORMERS_VERBOSITY =
    child_env.TRANSFORMERS_VERBOSITY || "error";
  child_env.TRANSFORMERS_NO_ADVISORY_WARNINGS =
    child_env.TRANSFORMERS_NO_ADVISORY_WARNINGS || "1";

  const future_warning_filter = "ignore::FutureWarning";
  if (child_env.PYTHONWARNINGS) {
    if (!child_env.PYTHONWARNINGS.includes(future_warning_filter)) {
      child_env.PYTHONWARNINGS = `${child_env.PYTHONWARNINGS},${future_warning_filter}`;
    }
  } else {
    child_env.PYTHONWARNINGS = future_warning_filter;
  }

  const python_path_segments = [];
  if (Array.isArray(env.python_path)) {
    env.python_path.forEach((entry) => {
      if (entry && !python_path_segments.includes(entry)) {
        python_path_segments.push(entry);
      }
    });
  }
  if (child_env.PYTHONPATH) {
    python_path_segments.push(child_env.PYTHONPATH);
  }
  if (python_path_segments.length > 0) {
    child_env.PYTHONPATH = python_path_segments.join(path.delimiter);
  }

  logger.info(
    `Launching IndexTTS runtime via ${chalk.gray(python_bin)} for ${chalk.green(path.basename(output_path))}.`,
  );

  await run_child_process(python_bin, args, {
    cwd: env.home_path,
    env: child_env,
    chalk,
    label: "INDEX_TTS",
  });
}

async function run_vibe_voice_engine({
  text,
  output_path,
  env,
  chalk,
  logger,
  python_bin,
}) {
  const script_path = path.resolve(
    __dirname,
    "..",
    "lib",
    "index_tts",
    "engines",
    "vibe_voice_local.py",
  );

  const args = [
    script_path,
    "--text",
    text,
    "--out",
    output_path,
    "--model-dir",
    env.model_dir,
    "--processor-dir",
    env.processor_dir,
    "--voice",
    env.voice_path,
    "--device",
    env.device_hint,
    "--cfg-scale",
    String(env.cfg_scale),
  ];

  if (Number.isFinite(env.max_new_tokens)) {
    args.push("--max-new-tokens", String(env.max_new_tokens));
  }
  if (Number.isFinite(env.ddpm_steps)) {
    args.push("--ddpm-steps", String(env.ddpm_steps));
  }
  if (env.use_half) {
    args.push("--use-half");
  }
  if (env.quiet) {
    args.push("--quiet");
  }

  const child_env = { ...process.env };
  child_env.VIBE_VOICE_MODEL_DIR = env.model_dir;
  child_env.VIBE_VOICE_PROCESSOR_DIR = env.processor_dir;

  logger.info(
    `Launching VibeVoice runtime via ${chalk.gray(python_bin)} for ${chalk.green(path.basename(output_path))}.`,
  );

  await run_child_process(python_bin, args, {
    cwd: env.model_dir,
    env: child_env,
    chalk,
    label: "VIBE_VOICE",
  });
}

async function run_piper_engine({
  text,
  model_path,
  output_path,
  speed,
  temperature,
  lang,
  device,
  chalk,
  logger,
}) {
  if (!model_path) {
    const help_link = "https://github.com/rhasspy/piper/blob/master/VOICES.md";
    throw new Error(
      `--piper-model is required when using the Piper engine. Download voices from ${help_link}.`,
    );
  }

  const absolute_model_path = path.resolve(process.cwd(), model_path);
  try {
    await fs.access(absolute_model_path);
  } catch (error) {
    throw new Error(
      `Piper model file not accessible: '${absolute_model_path}'.`,
    );
  }

  const piper_bin = process.env.PIPER_BIN || "piper";
  const args = ["--model", absolute_model_path, "--output_file", output_path];

  if (speed !== 1.0) {
    const length_scale = 1 / Number(speed);
    args.push("--length_scale", String(length_scale));
  }

  if (temperature !== 0.7) {
    logger.warn("Piper does not support temperature; ignoring provided value.");
  }

  if (lang && lang !== "auto") {
    logger.info(
      `Ensure the selected model matches language '${lang}' (no automatic switching).`,
    );
  }

  const child_env = { ...process.env };
  if (device === "cpu") {
    child_env.CUDA_VISIBLE_DEVICES = "";
  } else if (device && device.startsWith("cuda:")) {
    const [, index] = device.split(":");
    child_env.CUDA_VISIBLE_DEVICES = index || "0";
  }

  logger.info(`Running Piper via ${chalk.gray(piper_bin)}.`);

  await run_child_process(piper_bin, args, {
    cwd: process.cwd(),
    env: child_env,
    chalk,
    label: "PIPER",
    stdin: text,
  });
}

function run_child_process(command, args, options) {
  const { chalk, label, stdin, cwd, env } = options;

  return new Promise((resolve, reject) => {
    const child = spawn(command, args, {
      cwd,
      env,
      stdio: ["pipe", "pipe", "pipe"],
    });

    child.stdout.on("data", (chunk) => {
      process.stdout.write(chalk.gray(`[${label}] ${chunk.toString()}`));
    });

    child.stderr.on("data", (chunk) => {
      const text = chunk.toString();
      const colorize = pick_child_stderr_color({ label, text, chalk });
      process.stderr.write(colorize(`[${label}] ${text}`));
    });

    child.on("error", (error) => {
      reject(error);
    });

    child.on("close", (code) => {
      if (code === 0) {
        resolve();
      } else {
        reject(new Error(`${label} exited with code ${code}.`));
      }
    });

    if (typeof stdin === "string") {
      child.stdin.setDefaultEncoding("utf8");
      child.stdin.write(stdin);
      child.stdin.end();
    } else {
      child.stdin.end();
    }
  }).catch((error) => {
    if (error.code === "ENOENT") {
      const suggestion =
        command === "piper"
          ? "Install Piper locally or set PIPER_BIN to the binary path."
          : "Install Python 3.9-3.11 or set --python-bin to a compatible interpreter.";
      throw new Error(`${command} not found. ${suggestion}`);
    }
    throw error;
  });
}

function pick_child_stderr_color({ label, text, chalk }) {
  const normalized = text.trim().toLowerCase();

  if (!normalized) {
    return chalk.gray;
  }

  const is_error =
    normalized.includes("error") ||
    normalized.includes("exception") ||
    normalized.includes("traceback") ||
    normalized.includes("fatal") ||
    normalized.includes("crash") ||
    normalized.includes("cannot") ||
    normalized.includes("failed");
  if (is_error) {
    return chalk.red;
  }

  const is_warning =
    normalized.includes("warning") ||
    normalized.includes("deprecated") ||
    normalized.includes("caution") ||
    normalized.includes("futurewarning") ||
    normalized.includes("deprecation");
  if (is_warning) {
    return chalk.yellow;
  }

  if (label === "INDEX_TTS" || label === "XTTS" || label === "VIBE_VOICE") {
    return chalk.cyan;
  }

  return chalk.gray;
}

function collect_additional_python_candidates() {
  const candidates = [];
  const direct_paths = [];

  if (process.platform === "darwin") {
    const brew_prefixes = [
      process.env.HOMEBREW_PREFIX,
      "/opt/homebrew",
      "/usr/local",
    ].filter(Boolean);

    for (const prefix of brew_prefixes) {
      direct_paths.push(
        path.join(prefix, "opt", "python@3.11", "bin", "python3.11"),
        path.join(prefix, "opt", "python@3.10", "bin", "python3.10"),
        path.join(prefix, "bin", "python3.11"),
        path.join(prefix, "bin", "python3.10"),
        path.join(prefix, "bin", "python3.9"),
      );
    }
  }

  if (process.platform === "linux") {
    direct_paths.push(
      "/usr/bin/python3.11",
      "/usr/bin/python3.10",
      "/usr/bin/python3.9",
      "/usr/local/bin/python3.11",
      "/usr/local/bin/python3.10",
      "/usr/local/bin/python3.9",
    );
  }

  direct_paths.forEach((candidate) => {
    if (candidate && fs_sync.existsSync(candidate)) {
      candidates.push(candidate);
    }
  });

  const pyenv_root =
    process.env.PYENV_ROOT || path.join(os.homedir(), ".pyenv");
  const pyenv_versions_dir = path.join(pyenv_root, "versions");
  if (fs_sync.existsSync(pyenv_versions_dir)) {
    try {
      const entries = fs_sync.readdirSync(pyenv_versions_dir, {
        withFileTypes: true,
      });
      for (const entry of entries) {
        if (!entry.isDirectory()) {
          continue;
        }
        const version_name = entry.name;
        if (!/^3\.(9|10|11)(\.|$)/.test(version_name)) {
          continue;
        }
        const version_dir = path.join(pyenv_versions_dir, version_name, "bin");
        const python_candidates = [
          path.join(version_dir, "python3"),
          path.join(version_dir, "python"),
          path.join(version_dir, "python3.11"),
          path.join(version_dir, "python3.10"),
          path.join(version_dir, "python3.9"),
        ];
        python_candidates.forEach((candidate) => {
          if (fs_sync.existsSync(candidate)) {
            candidates.push(candidate);
          }
        });
      }
    } catch (error) {
      // ignore pyenv discovery issues
    }
  }

  const asdf_root =
    process.env.ASDF_DATA_DIR || path.join(os.homedir(), ".asdf");
  const asdf_python_dir = path.join(asdf_root, "installs", "python");
  if (fs_sync.existsSync(asdf_python_dir)) {
    try {
      const entries = fs_sync.readdirSync(asdf_python_dir, {
        withFileTypes: true,
      });
      for (const entry of entries) {
        if (!entry.isDirectory()) {
          continue;
        }
        const version_name = entry.name;
        if (!/^3\.(9|10|11)(\.|$)/.test(version_name)) {
          continue;
        }
        const python_candidates = [
          path.join(asdf_python_dir, version_name, "bin", "python3"),
          path.join(asdf_python_dir, version_name, "bin", "python"),
        ];
        python_candidates.forEach((candidate) => {
          if (fs_sync.existsSync(candidate)) {
            candidates.push(candidate);
          }
        });
      }
    } catch (error) {
      // ignore asdf discovery issues
    }
  }

  return candidates;
}

function resolve_python_runtime({
  requested_bin,
  logger,
  chalk,
  preferred_paths = [],
}) {
  const search_order = [];
  const additional_candidates = collect_additional_python_candidates();
  const normalized_preferred = Array.isArray(preferred_paths)
    ? preferred_paths.filter(Boolean)
    : [];

  if (requested_bin) {
    search_order.push(requested_bin);
  }
  if (process.env.PYTHON_BIN) {
    search_order.push(process.env.PYTHON_BIN);
  }
  normalized_preferred.forEach((candidate) => {
    search_order.push(candidate);
  });
  search_order.push(
    "python3.11",
    "python3.10",
    "python3.9",
    "python3",
    "python",
  );

  const unique_candidates = [];
  const seen = new Set();
  for (const extra of additional_candidates) {
    search_order.push(extra);
  }

  for (const candidate of search_order) {
    if (!candidate || seen.has(candidate)) {
      continue;
    }
    seen.add(candidate);
    unique_candidates.push(candidate);
  }

  for (const candidate of unique_candidates) {
    const version_info = inspect_python_version(candidate);

    if (version_info?.not_found) {
      if (requested_bin && candidate === requested_bin) {
        throw new Error(
          `Python runtime '${candidate}' not found. Install Python 3.9-3.11 and re-run with --python-bin.`,
        );
      }
      continue;
    }

    if (version_info?.error) {
      if (requested_bin && candidate === requested_bin) {
        throw new Error(
          `Failed to inspect --python-bin '${candidate}': ${version_info.error.message}`,
        );
      }
      continue;
    }

    if (!version_info) {
      continue;
    }

    if (python_version_supported(version_info.version)) {
      logger.info(
        `Python interpreter: ${chalk.magenta(candidate)} (${chalk.green(version_info.version_text)})`,
      );
      return {
        command: candidate,
        version: version_info.version,
        version_text: version_info.version_text,
      };
    }

    if (requested_bin && candidate === requested_bin) {
      throw new Error(
        `Python runtime '${candidate}' reports ${version_info.version_text}. Install Python 3.9-3.11 and re-run with --python-bin.`,
      );
    }

    if (process.env.PYTHON_BIN && candidate === process.env.PYTHON_BIN) {
      logger.warn(
        `PYTHON_BIN points to ${version_info.version_text}, which falls outside the supported 3.9-3.11 range. Ignoring.`,
      );
    }
  }

  throw new Error(
    "Unable to locate a Python 3.9-3.11 interpreter for XTTS. Install Python 3.10/3.11 and re-run with --python-bin, or switch to --engine piper.",
  );
}

function inspect_python_version(command) {
  try {
    const result = spawnSync(command, ["--version"], { encoding: "utf8" });
    if (result.error) {
      if (result.error.code === "ENOENT") {
        return { not_found: true, error: result.error };
      }
      return { error: result.error };
    }
    const combined_output =
      `${result.stdout || ""}${result.stderr || ""}`.trim();
    if (!combined_output) {
      return { error: new Error("Empty version output") };
    }
    const match = combined_output.match(/Python\s+(\d+)\.(\d+)\.(\d+)/i);
    if (!match) {
      return {
        error: new Error(`Unexpected version string: ${combined_output}`),
      };
    }
    return {
      version: {
        major: Number(match[1]),
        minor: Number(match[2]),
        patch: Number(match[3]),
      },
      version_text: combined_output,
    };
  } catch (error) {
    return { error };
  }
}

function python_version_supported(version) {
  if (!version || version.major !== 3) {
    return false;
  }
  return version.minor >= 9 && version.minor <= 11;
}
